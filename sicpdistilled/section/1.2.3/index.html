<!DOCTYPE html>
<html>
<head>
<meta charset='utf-8'>
<meta content='IE=edge,chrome=1' http-equiv='X-UA-Compatible'>
<meta content='width=device-width, initial-scale=1' name='viewport'>
<title>SICP Distilled</title>
<link href='http://fonts.googleapis.com/css?family=Droid+Serif' rel='stylesheet' type='text/css'>
<link href="/sicpdistilled/stylesheets/all-e81cfb05.css" rel="stylesheet" />
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script type='text/x-mathjax-config'>
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
</head>
</html>
<body>
<div class='menu--mobile js-mobile-nav' data-target='menu'>Menu</div>
<div class='menu'>
<a href="/sicpdistilled/"><img alt="SICP Distilled" class="logo" src="/sicpdistilled/images/sicp2-07ad7dbe.jpg" />
</a><h1 class='menu__title done'>
<a href="/sicpdistilled/">SICP Distilled
</a></h1>
<ul class='menu__list'>
<li class='done'>
<a href="/sicpdistilled/section/licence"><img alt="CC by-sa" style="border-width: 0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />
License
</a></li>
<li class='done'>
<a href="#{http_prefix}/section/donate"><img alt="MSF" width="88px" src="/sicpdistilled/images/msf-b09b7038.jpg" />
Donate
</a></li>
</ul>
<h2>Ch1 - Building Abstractions With Functions</h2>
<ul class='menu__list'>
<li class='done'>
<a href="/sicpdistilled/section/1-distilled">Chapter 1 Distilled
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1-intro">Introduction
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1">1.1 - The Elements Of Programming
</a></li>
<ul class='menu__list_2'>
<li class='done'>
<a href="/sicpdistilled/section/1.1.1">Expressions
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.2">Naming and the Environment
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.3">Evaluating Combinations
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.4">Defining New Functions
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.5">The Substitution Model
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1-exercises">Exercises
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.6a">Predicates
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.6b">Conditional Expressions
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.7">Example: Newton’s Method
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.1.8">Functions as Black-Box Abstractions
</a></li>
</ul>
<li class='done'>
<a href="/sicpdistilled/section/1.2">1.2 - Procedures and the Processes They Generate
</a></li>
<ul class='menu__list_2'>
<li class='done'>
<a href="/sicpdistilled/section/1.2.1">Linear Recursion and Iteration
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.2.2">Tree Recursion
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.2.3">Orders of Growth
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/1.2.4">Exponentiation
</a></li>
<il class='done'>
<a href="/sicpdistilled/section/1.2.5">Greatest Common Divisors
</a></il>
<li class='done'>
<a href="/sicpdistilled/section/1.2.6">Example: Testing For Primality
</a></li>
</ul>
<li class='done'>
<a href="/sicpdistilled/section/1.3-higher-order">1.3 Higher Order Functions
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/project-blackjack">Project - Blackjack
</a></li>
</ul>
<h2>Ch2 - Building Abstractions With Data</h2>
<ul class='menu__list'>
<li class='done'>
<a href="/sicpdistilled/section/2-distilled">Chapter 2 Distilled
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/2-intro">Introduction
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/2-data-abstraction">Data Abstraction
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/2-nothing">Everything From Nothing
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/2-abstractions">Abstractions In Clojure
</a></li>
<li>
<a href="/sicpdistilled/section/2-data-structures">Clojure's Data Structures
</a></li>
<li>
<a href="/sicpdistilled/section/2-data-abstraction-clj">Data Abstraction, Revisited
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/2-escher">Escher
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/project-escher">Project - Escher
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/2-symbolic">Symbolic Data
</a></li>
<li>
<a href="/sicpdistilled/section/2-sets">Representing Sets
</a></li>
<li>
<a href="/sicpdistilled/section/2-escher">Huffman Encoding Trees
</a></li>
<li>
<a href="/sicpdistilled/section/2-zippers">Zippers
</a></li>
</ul>
<h2>Ch3 - Modularity, Objects, and State</h2>
<h2>Ch4 - Metalinguistic Abstraction</h2>
<ul class='menu__list'>
<li class='done'>
<a href="/sicpdistilled/section/4.1">4.1 - The Metacircular Evaluator
</a></li>
<li class='done'>
<a href="/sicpdistilled/section/halting">The Halting Problem
</a></li>
<li>
<a href="/sicpdistilled/section/y">The Y Combinator
</a></li>
<li>
<a href="/sicpdistilled/section/4.2">4.2 - Lazy Evaluation
</a></li>
<li>
<a href="/sicpdistilled/section/4.3">4.3 - Nondeterministic Computing
</a></li>
<li>
<a href="/sicpdistilled/section/4.4">4.4 - Logic Programming
</a></li>
</ul>
</div>
<div class='container menu--push'>
<h1>Orders of Growth</h1>

<p>The previous examples illustrate that processes can differ
considerably in the rates at which they consume computational
resources. One convenient way to describe this difference is to use
the notion of order of growth to obtain a gross measure of the
resources required by a process as the inputs become larger</p>

<p>Let n be a parameter that measures the size of the problem, and let
<code>R(n)</code> be the amount of resources the process requires for a problem
of size <code>n</code>. In our previous examples we took <code>n</code> to be the number for
which a given function is to be computed, but there are other
possibilities. For instance, if our goal is to compute an
approximation to the square root of a number, we might take <code>n</code> to be
the number of digits accuracy required.  For matrix multiplication we
might take <code>n</code> to be the number of rows in the matrices. In general
there are a number of properties of the problem with respect to which
it will be desirable to analyze a given process.  Similarly, <code>R(n)</code>
might measure the number of internal storage registers used, the
number of elementary machine operations performed, and so on. In
computers that do only a fixed number of operations at a time, the
time required will be proportional to the number of elementary machine
operations performed.</p>

<p>We say that $R(n)$ has order of growth $\Theta(f (n))$, written $R(n)
= \Theta(f (n))$ (pronounced &quot;theta of f of n&quot;), if there are positive
constants $k_1$ and $k_2$ independent of $n$ such that $k_1 f(n) ≤
R(n) ≤ k_2 f (n)$ for any sufficiently large value of $n$. (In other
words, for large $n$, the value $R(n)$ is sandwiched between $k_1
f(n)$ and $k_2 f(n)$.)</p>

<p>For instance, with the linear recursive process for computing
factorial described in Section 1.2.1 the number of steps grows
proportionally to the input n. Thus, the steps required for this
process grows as $\Theta(n)$.  We also saw that the space required
grows as $\Theta(n)$. For the iterative factorial, the number of steps
is still $\Theta(n)$ but the space is $\Theta(1)$ (ie constant).</p>

<p>Orders of growth provide only a crude description of the behavior of a
process. For example, a process requiring $n^2$ steps and a process
requiring $1000n^2$ steps and a process requiring $3n^2 + 10n + 17$
steps all have $\Theta(n^2)$ order of growth. On the other hand, order
of growth provides a useful indication of how we may expect the
behavior of the process to change as we change the size of the
problem.</p>

<p>For a $\Theta(n)$ (linear) process, doubling the size will roughly
double the amount of resources used.</p>

<p>For an exponential process, each increment in problem size will
multiply the resource utilization by a constant factor.</p>

<p>We will examine algorithms whose order of growth is logarithmic, so
that doubling the problem size increases the resource requirement by a
constant amount.</p>

<h1>Ex 1.15</h1>

<p>Exercise 1.15: The sine of an angle (specified in radians) can be
computed by making use of the approximation sin x ≈ x if x is
sufficiently small, and the trigonometric identity</p>

<p>$$ \sin x = 3 \sin \frac{x}{3} - 4 \sin^{3} \frac{x}{3} $$</p>

<p>to reduce the size of the argument of sin. (For purposes of this
exercise an angle is considered “sufficiently small” if its magnitude
is not greater than 0.1 radians.) These ideas are incorporated in the
following procedures:</p>

<pre><code class="clojure">(defn cube [x]
  (* x x x))

(defn p [x]
  (- (* 3 x) (* 4 (cube x))))

(defn sine [angle]
  (if (not (&gt; (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
</code></pre>

<p>a. How many times is the procedure p applied when (sine 12.15) is
evaluated?</p>

<p>b. What is the order of growth in space and number of steps (as a
function of a) used by the process generated by the sine procedure
when (sine a) is evaluated?</p>

</div>
<script src='https://cdn.polyfill.io/v1/polyfill.min.js'></script>
<script src="/sicpdistilled/javascripts/all-0c20c227.js"></script>
<link href='http://app.klipse.tech/css/codemirror.css' rel='stylesheet' type='text/css'>
<script>
  window.klipse_settings = {
    selector: 'code.clojure'
  };
</script>
<script src='http://app.klipse.tech/dev/js/klipse_plugin.js'></script>
</body>
